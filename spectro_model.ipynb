{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"SC8jWKdbUZ98"},"outputs":[],"source":["#import relevant libraries\n","import matplotlib.pyplot as plt\n","from statistics import mean\n","import numpy as np\n","import os\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import models,layers\n","import seaborn as sns \n","from sklearn.metrics import confusion_matrix,accuracy_score\n","from sklearn.metrics import f1_score, precision_score, recall_score, classification_report"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"hR8VEdhGBZKW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#hyperparameter tuning\n","HP_epochs = 30\n","HP_learning_rate = 0.000001\n","HP_batch_size = 1\n","\n","HP_optimizer = keras.optimizers.Adam(learning_rate = HP_learning_rate)\n","HP_loss = 'sparse_categorical_crossentropy'"],"metadata":{"id":"vvhrkCNuoumv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#numeric representation of image\n","def get_arrays(folder):\n","    arr = []\n","    for i in os.listdir(folder):\n","        img = Image.open(os.path.join(folder,i))\n","        img_arr = np.array(img)\n","        rshp_arr = img_arr.reshape(-1,1)\n","        arr.append(rshp_arr)\n","    arr = np.squeeze(arr)\n","    return np.array(arr)"],"metadata":{"id":"8qah2rjYBxug"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#initializing input data\n","x = get_arrays(\"/content/drive/MyDrive/GAIP_Project/AudioClassification/Spectrogram\")\n","print(\"Shape of input data is:\",x.shape)\n","print(x)"],"metadata":{"id":"plIzZhT3B0BF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#initializing output data\n","y = np.array([0]*227+[1]*318)\n","print(\"Shape of output data is:\",y.shape)\n","print(y)"],"metadata":{"id":"QEhNHe7lB2WB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#scaling and feature reduction\n","se = StandardScaler()\n","x = se.fit_transform(x)\n","pca = PCA(0.90)\n","pca.fit(x)\n","pc_x = pca.transform(x)\n","\n","print(\"Shape of input data is: \",pc_x.shape)\n","print(x)"],"metadata":{"id":"_VkvFmeTIV8o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#splitting data into train and test\n","X_train,X_test,y_train,y_test = train_test_split(pc_x,y,train_size = 0.7,random_state = 2022)"],"metadata":{"id":"J0ZkbUtgI4g4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#constructing model\n","network=models.Sequential()\n","network.add(layers.Dense(400,activation='relu'))\n","network.add(layers.Dense(200,activation='relu'))\n","network.add(layers.Dense(2,activation='softmax'))"],"metadata":{"id":"fJU9u3lYJ5AX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#compiling model\n","network.compile(optimizer = HP_optimizer,loss = HP_loss,metrics = ['accuracy'])"],"metadata":{"id":"gLUP2bwhKKXv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#model training and fit\n","history = network.fit(X_train,y_train.reshape(-1,1),epochs = HP_epochs,batch_size = HP_batch_size,validation_data = (X_test,y_test.reshape(-1,1)),verbose = False)"],"metadata":{"id":"CxuoCtuFKNO8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#visualization\n","acc = history.history['accuracy'] \n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss'] \n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(HP_epochs)\n","\n","plt.figure(figsize=(8,6)) \n","plt.plot(epochs_range, acc, label='Training Accuracy') \n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right') \n","plt.title('Training and Validation Accuracy')\n","plt.show()\n","\n","plt.figure(figsize=(8,6)) \n","plt.plot(epochs_range, loss, label='Training Loss') \n","plt.plot(epochs_range, val_loss, label='Validation Loss') \n","plt.legend(loc='upper right') \n","plt.title('Training and Validation Loss') \n","plt.show()"],"metadata":{"id":"9QJ-chXmKfRR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#training data prediction\n","preds = network.predict(X_train)\n","preds = np.argmax(preds,axis=1)\n","\n","\n","#test data prediction\n","test_preds = network.predict(X_test)\n","test_preds = np.argmax(test_preds,axis=1)"],"metadata":{"id":"EHo8xhzPKz2L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#confusion matrix for training data\n","sns.heatmap(confusion_matrix(y_train,preds),annot=True)\n","acc = accuracy_score(y_train,preds)\n","acc"],"metadata":{"id":"0LstwKOdLcB-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#confusion matrix for testing data\n","sns.heatmap(confusion_matrix(y_test,test_preds),annot=True)\n","val_acc = accuracy_score(y_test,test_preds)\n","val_acc"],"metadata":{"id":"wFXfezCeL05K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#network summary and metrics evaluation\n","report = classification_report( y_test, test_preds)\n","print(network.summary())\n","print(report)"],"metadata":{"id":"YsMfZ9hHMEQx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#prediction analysis\n","person={\n","    0: 'robot',\n","    1: 'human'\n","}\n","for i in range(len(test_preds)):\n","  print(f\"Actual: {person[y_test[i]]}; Predicted: {person[test_preds[i]]}\")"],"metadata":{"id":"yUXAkmqfMkWw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#saving model\n","network.save(\"/content/drive/MyDrive/GAIP_Project/AudioClassification/audio_model.h5\", history)\n","print(\"Model Saved\")"],"metadata":{"id":"MXKk1WhOMwxV"},"execution_count":null,"outputs":[]}]}